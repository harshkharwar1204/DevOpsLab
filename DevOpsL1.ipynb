{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMokCaPyMX8oAclHJ6daf80",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshkharwar1204/DevOpsLab/blob/main/DevOpsL1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0qDjUFXS8z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3ff41f-ba74-443a-9be0-37718d0019f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully saved to books.csv ✅\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "def scrape_books(url):\n",
        "    \"\"\"\n",
        "    Scrapes book titles, prices, and ratings from 'books.toscrape.com'.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the website to scrape.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of lists, where each inner list contains the\n",
        "              title, price, and rating of a book. Returns None on failure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        # Raise an exception for bad status codes (4xx or 5xx)\n",
        "        response.raise_for_status()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching the URL: {e}\")\n",
        "        return None\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Find all book containers on the page\n",
        "    articles = soup.find_all('article', class_='product_pod')\n",
        "\n",
        "    scraped_data = []\n",
        "\n",
        "    for book in articles:\n",
        "        # Extract title from the 'a' tag's title attribute\n",
        "        title = book.h3.a['title']\n",
        "\n",
        "        # Extract price from the element with the 'price_color' class\n",
        "        price = book.find('p', class_='price_color').get_text()\n",
        "\n",
        "        # Extract star rating from the 'p' tag's class attribute\n",
        "        rating_class = book.find('p', class_='star-rating')['class']\n",
        "        # The rating is the second class in the list (e.g., ['star-rating', 'Three'])\n",
        "        rating = f\"{rating_class[1]} out of Five\"\n",
        "\n",
        "        scraped_data.append([title, price, rating])\n",
        "\n",
        "    return scraped_data\n",
        "\n",
        "def save_to_csv(data, filename=\"books.csv\"):\n",
        "    \"\"\"\n",
        "    Saves the scraped data to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        data (list): The list of book data to save.\n",
        "        filename (str): The name of the output CSV file.\n",
        "    \"\"\"\n",
        "    if not data:\n",
        "        print(\"No data to save.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
        "            writer = csv.writer(file)\n",
        "            # Write the header row\n",
        "            writer.writerow(['Title', 'Price', 'Rating'])\n",
        "            # Write all the book data\n",
        "            writer.writerows(data)\n",
        "        print(f\"Data successfully saved to {filename} ✅\")\n",
        "    except IOError as e:\n",
        "        print(f\"Error writing to file: {e}\")\n",
        "\n",
        "# --- Main execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    TARGET_URL = 'http://books.toscrape.com/'\n",
        "    book_data = scrape_books(TARGET_URL)\n",
        "\n",
        "    if book_data:\n",
        "        save_to_csv(book_data)"
      ]
    }
  ]
}